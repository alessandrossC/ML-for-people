{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrossC/ML-for-people/blob/main/%22HW_2_4_%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%B8_%D0%B1%D1%83%D1%81%D1%82%D0%B8%D0%BD%D0%B3%D1%83_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В цьому домашньому завданні ми знову працюємо з даними з нашого змагання [\"Bank Customer Churn Prediction (DLU Course)\"](https://www.kaggle.com/t/7c080c5d8ec64364a93cf4e8f880b6a0).\n",
        "\n",
        "Тут ми побудуємо рішення задачі класифікації з використанням алгоритмів бустингу: XGBoost та LightGBM, а також використаємо бібліотеку HyperOpt для оптимізації гіперпараметрів."
      ],
      "metadata": {
        "id": "fDefDHQt8LXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Зчитайте дані `train.csv` в змінну `raw_df` та скористайтесь наведеним кодом нижче аби розділити дані на трнувальні та валідаційні і розділити дані на ознаки з матириці Х та цільову змінну. Назви змінних `train_inputs, train_targets, train_inputs, train_targets` можна змінити на ті, які Вам зручно.\n",
        "\n",
        "  Наведений скрипт - частина отриманого мною скрипта для обробки даних. Ми тут не викнуємо масштабування та обробку категоріальних змінних, бо хочемо це делегувати алгоритмам, які будемо використовувати. Якщо щось не розумієте в наведених скриптах, рекомендую розібратись: навичка читати код - важлива складова роботи в машинному навчанні."
      ],
      "metadata": {
        "id": "LhivzW9W8-Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JmLIpZ1sHYc",
        "outputId": "917c8cb5-8c7c-40fb-e14b-a81400fb6a66"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple, Dict, Any\n",
        "\n",
        "raw_df = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Визначення цільової змінної\n",
        "target_col = \"Exited\"\n",
        "\n",
        "# Визначення вхідних ознак (усі колонки, крім цільової та неінформативних ідентифікаторів)\n",
        "input_cols = [col for col in raw_df.columns if col not in [target_col, \"id\", \"CustomerId\", \"Surname\"]]\n",
        "\n",
        "# Визначення категоріальних змінних\n",
        "categorical_cols = [col for col in input_cols if raw_df[col].dtype == 'object']\n",
        "\n",
        "\n",
        "def split_train_val(df: pd.DataFrame, target_col: str, test_size: float = 0.2, random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split the dataframe into training and validation sets.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The raw dataframe.\n",
        "        target_col (str): The target column for stratification.\n",
        "        test_size (float): The proportion of the dataset to include in the validation split.\n",
        "        random_state (int): Random state for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.DataFrame]: Training and validation dataframes.\n",
        "    \"\"\"\n",
        "    train_df, val_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df[target_col])\n",
        "    return train_df, val_df\n",
        "\n",
        "\n",
        "def separate_inputs_targets(df: pd.DataFrame, input_cols: list, target_col: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "    \"\"\"\n",
        "    Separate inputs and targets from the dataframe.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataframe.\n",
        "        input_cols (list): List of input columns.\n",
        "        target_col (str): Target column.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.Series]: DataFrame of inputs and Series of targets.\n",
        "    \"\"\"\n",
        "    inputs = df[input_cols].copy()\n",
        "    targets = df[target_col].copy()\n",
        "    return inputs, targets"
      ],
      "metadata": {
        "id": "cKE8RTPf6CRD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Розділення на тренувальні та валідаційні набори\n",
        "train_df, val_df = split_train_val(raw_df, target_col)\n",
        "\n",
        "# Розділення на ознаки та цільову змінну\n",
        "train_inputs, train_targets = separate_inputs_targets(train_df, input_cols, target_col)\n",
        "val_inputs, val_targets = separate_inputs_targets(val_df, input_cols, target_col)"
      ],
      "metadata": {
        "id": "-bHdMJVB4xQR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. В тренувальному та валідаційному наборі перетворіть категоріальні ознаки на тип `category`. Можна це зробити двома способами:\n",
        " 1. `df[col_name].astype('category')`, як було продемонстровано в лекції\n",
        " 2. використовуючи метод `pd.Categorical(df[col_name])`"
      ],
      "metadata": {
        "id": "cq0JU7MqHgp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Перетворення категоріальних ознак на тип category (перший підхід)\n",
        "for col in categorical_cols:\n",
        "    train_inputs[col] = train_inputs[col].astype('category')\n",
        "\n",
        "# Перетворення категоріальних ознак на тип category (другий підхід)\n",
        "for col in categorical_cols:\n",
        "    val_inputs[col] = pd.Categorical(val_inputs[col])\n",
        "\n",
        "# Виведення розміру отриманих наборів\n",
        "print(train_inputs.shape, train_targets.shape, val_inputs.shape, val_targets.shape)"
      ],
      "metadata": {
        "id": "UPmqo-Mr4yUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fdf0d39-9c2f-4331-f722-e98f3d4b35b2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12000, 10) (12000,) (3000, 10) (3000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Навчіть на отриманих даних модель `XGBoostClassifier`. Параметри алгоритму встановіть на свій розсуд, ми далі будемо їх тюнити. Рекомендую тренувати не дуже складну модель.\n",
        "\n",
        "  Опис всіх конфігураційних параметрів XGBoostClassifier - тут https://xgboost.readthedocs.io/en/stable/parameter.html#global-config\n",
        "\n",
        "  **Важливо:** зробіть такі налаштування `XGBoostClassifier` аби він самостійно обробляв незаповнені значення в даних і обробляв категоріальні колонки.\n",
        "\n",
        "  Можна також, якщо працюєте в Google Colab, увімкнути можливість використання GPU (`Runtime -> Change runtime type -> T4 GPU`) і встановити параметр `device='cuda'` в `XGBoostClassifier` для пришвидшення тренування бустинг моделі.\n",
        "  \n",
        "  Після тренування моделі\n",
        "  1. Виміряйте точність з допомогою AUROC на тренувальному та валідаційному наборах.\n",
        "  2. Зробіть висновок про отриману модель: вона хороша/погана, чи є high bias/high variance?\n",
        "  3. Порівняйте якість цієї моделі з тою, що ви отрмали з використанням DecisionTrees раніше. Чи вийшло покращити якість?"
      ],
      "metadata": {
        "id": "_LxWkv4o-wMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Ініціалізація моделі XGBoostClassifier\n",
        "xgb_model = XGBClassifier(\n",
        "    use_label_encoder=False,  # Вимикає попередження про кодування міток\n",
        "    eval_metric='logloss',  # Вибираємо функцію втрат логарифмічну\n",
        "    missing=np.nan,  # Обробка пропущених значень\n",
        "    tree_method='hist',  # Оптимізація швидкості\n",
        "    enable_categorical=True,  # Автоматична обробка категоріальних змінних\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Навчання моделі\n",
        "xgb_model.fit(train_inputs, train_targets)\n",
        "\n",
        "# Прогнози ймовірностей для оцінки AUROC\n",
        "train_preds = xgb_model.predict_proba(train_inputs)[:, 1]\n",
        "val_preds = xgb_model.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "# Обчислення AUROC\n",
        "train_auc = roc_auc_score(train_targets, train_preds)\n",
        "val_auc = roc_auc_score(val_targets, val_preds)\n",
        "\n",
        "print(f\"AUROC на тренувальній вибірці: {train_auc}\")\n",
        "print(f\"AUROC на валідаційній вибірці: {val_auc}\")"
      ],
      "metadata": {
        "id": "_5rDqdDP41hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e523c574-9c6b-4c98-9b96-a890716e43a6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:55:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC на тренувальній вибірці: 0.9917909049264981\n",
            "AUROC на валідаційній вибірці: 0.921015844708142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так, модель показує дуже хороші результати. Значення AUROC > 0.9 вказує на високу якість класифікації.\n",
        "\n",
        "Різниця між AUROC на тренуванні (0.9918) і валідації (0.9210) вказує на певне перенавчання (overfitting)\n",
        "\n",
        "XGBoost AUROC: 0.921\n",
        "DecisionTree AUROC: 0.915\n",
        "\n",
        "XGBoost може бути перенавченим, через що не дає значного приросту на валідації"
      ],
      "metadata": {
        "id": "XR60uYr4vcnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Використовуючи бібліотеку `Hyperopt` і приклад пошуку гіперпараметрів для `XGBoostClassifier` з лекції знайдіть оптимальні значення гіперпараметрів `XGBoostClassifier` для нашої задачі. Задайте свою сітку гіперпараметрів виходячи з тих параметрів, які ви б хотіли перебрати. Поставте кількість раундів в підборі гіперпараметрів рівну **20**.\n",
        "\n",
        "  **Увага!** Для того, аби скористатись hyperopt, нам треба задати функцію `objective`. В ній ми маємо задати loss - це може будь-яка метрика, але бажано використовувтаи ту, яка цільова в вашій задачі. Чим менший лосс - тим ліпша модель на думку hyperopt. Тож, тут нам треба задати loss - негативне значення AUROC. В лекції ми натомість використовували Accuracy.\n",
        "\n",
        "  Після успішного завершення пошуку оптимальних гіперпараметрів\n",
        "    - виведіть найкращі значення гіперпараметрів\n",
        "    - створіть в окремій зміній `final_clf` модель `XGBoostClassifier` з найкращими гіперпараметрами\n",
        "    - навчіть модель `final_clf`\n",
        "    - оцініть якість моделі `final_clf` на тренувальній і валідаційній вибірках з допомогою AUROC.\n",
        "    - зробіть висновок про якість моделі. Чи стала вона краще порівняно з попереднім пунктом (2) цього завдання?"
      ],
      "metadata": {
        "id": "U4hm5qYs_f7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyperopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fqRdOpKwkRQ",
        "outputId": "4f2a968d-a33c-4744-cad9-ad5c5f2324aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.11/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt) (4.67.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, hp, Trials\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Функція для оптимізації\n",
        "def objective(params):\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=int(params['n_estimators']),\n",
        "        max_depth=int(params['max_depth']),\n",
        "        learning_rate=params['learning_rate'],\n",
        "        subsample=params['subsample'],\n",
        "        colsample_bytree=params['colsample_bytree'],\n",
        "        reg_lambda=params['reg_lambda'],\n",
        "        reg_alpha=params['reg_alpha'],\n",
        "        missing=np.nan,\n",
        "        tree_method='hist',\n",
        "        enable_categorical=True,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(train_inputs, train_targets)\n",
        "    val_preds = model.predict_proba(val_inputs)[:, 1]\n",
        "    val_auc = roc_auc_score(val_targets, val_preds)\n",
        "\n",
        "    return -val_auc  # Hyperopt мінімізує значення, тому беремо негативний AUROC\n",
        "\n",
        "# Простір пошуку гіперпараметрів\n",
        "param_space = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 300, 10),\n",
        "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n",
        "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0, 10),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0, 10)\n",
        "}\n",
        "\n",
        "# Запуск Hyperopt для пошуку оптимальних параметрів\n",
        "trials = Trials()\n",
        "best_params = fmin(fn=objective, space=param_space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
        "\n",
        "# Конвертація параметрів у правильний формат\n",
        "best_params['n_estimators'] = int(best_params['n_estimators'])\n",
        "best_params['max_depth'] = int(best_params['max_depth'])\n",
        "\n",
        "# Виведення найкращих параметрів\n",
        "print(\"Найкращі гіперпараметри:\")\n",
        "best_params"
      ],
      "metadata": {
        "id": "WhR1g9B4433r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81860dff-6357-4d81-9003-dd6d17c3e2a8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  3.43trial/s, best loss: -0.9368996501817684]\n",
            "Найкращі гіперпараметри:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.662321366340816,\n",
              " 'learning_rate': 0.12151493914778948,\n",
              " 'max_depth': 3,\n",
              " 'n_estimators': 120,\n",
              " 'reg_alpha': 3.6164607204061614,\n",
              " 'reg_lambda': 5.252743948749027,\n",
              " 'subsample': 0.7645380854254465}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ініціалізація моделі XGBoostClassifier з найкращими параметрами\n",
        "final_clf = XGBClassifier(\n",
        "    n_estimators=best_params['n_estimators'],\n",
        "    max_depth=best_params['max_depth'],\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    subsample=best_params['subsample'],\n",
        "    colsample_bytree=best_params['colsample_bytree'],\n",
        "    reg_lambda=best_params['reg_lambda'],\n",
        "    reg_alpha=best_params['reg_alpha'],\n",
        "    missing=np.nan,\n",
        "    tree_method='hist',\n",
        "    enable_categorical=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Навчання моделі\n",
        "final_clf.fit(train_inputs, train_targets)\n",
        "\n",
        "# Прогнози ймовірностей для оцінки AUROC\n",
        "train_preds_final = final_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_preds_final = final_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "# Обчислення AUROC\n",
        "train_auc_final = roc_auc_score(train_targets, train_preds_final)\n",
        "val_auc_final = roc_auc_score(val_targets, val_preds_final)\n",
        "\n",
        "# Виведення результатів\n",
        "print(f\"AUROC на тренувальній вибірці: {train_auc_final}\")\n",
        "print(f\"AUROC на валідаційній вибірці: {val_auc_final}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH6zJMS6xtBj",
        "outputId": "6782e7e3-415a-414b-d8d6-0990fd72e08f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC на тренувальній вибірці: 0.9426115895042448\n",
            "AUROC на валідаційній вибірці: 0.9368996501817684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Менше перенавчання – різниця між Train і Validation AUROC стала меншою.\n",
        "Validation AUROC підвищився з 0.9210 до 0.9369.\n",
        "Модель стала більш узагальненою, тому що її продуктивність на валідації ближча до тренувальної."
      ],
      "metadata": {
        "id": "nOPzfCnTyJMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Навчіть на наших даних модель LightGBM. Параметри алгоритму встановіть на свій розсуд, ми далі будемо їх тюнити. Рекомендую тренувати не дуже складну модель.\n",
        "\n",
        "  Опис всіх конфігураційних параметрів LightGBM - тут https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
        "\n",
        "  **Важливо:** зробіть такі налаштування LightGBM аби він самостійно обробляв незаповнені значення в даних і обробляв категоріальні колонки.\n",
        "\n",
        "  Аби передати категоріальні колонки в LightGBM - необхідно виявити їх індекси і передати в параметрі `cat_feature=cat_feature_indexes`\n",
        "\n",
        "  Після тренування моделі\n",
        "  1. Виміряйте точність з допомогою AUROC на тренувальному та валідаційному наборах.\n",
        "  2. Зробіть висновок про отриману модель: вона хороша/погана, чи є high bias/high variance?\n",
        "  3. Порівняйте якість цієї моделі з тою, що ви отрмали з використанням XGBoostClassifier раніше. Чи вийшло покращити якість?"
      ],
      "metadata": {
        "id": "Vg77SVWrBBmU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C-9aZn4d45No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Використовуючи бібліотеку `Hyperopt` і приклад пошуку гіперпараметрів для `LightGBM` з лекції знайдіть оптимальні значення гіперпараметрів `LightGBM` для нашої задачі. Задайте свою сітку гіперпараметрів виходячи з тих параметрів, які ви б хотіли перебрати. Поставте кількість раундів в підборі гіперпараметрів рівну **10**.\n",
        "\n",
        "  **Увага!** Для того, аби скористатись hyperopt, нам треба задати функцію `objective`. І тут ми також ставимо loss - негативне значення AUROC, як і при пошуці гіперпараметрів для XGBoost. До речі, можна спробувати написати код так, аби в objective передавати лише модель і не писати схожий код двічі :)\n",
        "\n",
        "  Після успішного завершення пошуку оптимальних гіперпараметрів\n",
        "    - виведіть найкращі значення гіперпараметрів\n",
        "    - створіть в окремій зміній `final_lgb_clf` модель `LightGBM` з найкращими гіперпараметрами\n",
        "    - навчіть модель `final_lgb_clf`\n",
        "    - оцініть якість моделі `final_lgb_clf` на тренувальній і валідаційній вибірках з допомогою AUROC.\n",
        "    - зробіть висновок про якість моделі. Чи стала вона краще порівняно з попереднім пунктом (4) цього завдання?"
      ],
      "metadata": {
        "id": "nCnkGD_sEW1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "id": "cfMQKA4D47Rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34df8f05-4787-4b41-c5c2-9068e9c187a9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "sudo apt-get update\n",
        "sudo apt-get install -y build-essential cmake git wget unzip\n",
        "sudo apt-get install -y libboost-dev libboost-system-dev libboost-filesystem-dev\n",
        "sudo apt-get install -y libboost-iostreams-dev libboost-program-options-dev libboost-regex-dev\n",
        "sudo apt-get install -y libboost-thread-dev libboost-chrono-dev libboost-date-time-dev\n",
        "sudo apt-get install -y libboost-atomic-dev libboost-serialization-dev\n",
        "sudo apt-get install -y python3-pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0DkxtPXlyxQN",
        "outputId": "49720989-8843-4f12-c8f3-695782144bba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,317 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,661 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,698 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,610 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,939 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 21.4 MB in 2s (9,256 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libboost-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-dev set to manually installed.\n",
            "libboost-filesystem-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-filesystem-dev set to manually installed.\n",
            "libboost-system-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-system-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libboost-program-options-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-program-options-dev set to manually installed.\n",
            "libboost-regex-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-regex-dev set to manually installed.\n",
            "libboost-iostreams-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-iostreams-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libboost-thread-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-thread-dev set to manually installed.\n",
            "libboost-chrono-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-chrono-dev set to manually installed.\n",
            "libboost-date-time-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-date-time-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libboost-atomic-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-atomic-dev set to manually installed.\n",
            "libboost-serialization-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-serialization-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,968 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.2 [340 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.5 [1,306 kB]\n",
            "Fetched 1,677 kB in 1s (2,154 kB/s)\n",
            "Selecting previously unselected package python3-setuptools.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 124926 files and directories currently installed.)\r\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\r\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\r\n",
            "Selecting previously unselected package python3-wheel.\r\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\r\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\r\n",
            "Selecting previously unselected package python3-pip.\r\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.5_all.deb ...\r\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\r\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\r\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\r\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\r\n",
            "Processing triggers for man-db (2.10.2-1) ...\r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "sudo apt-get install -y ocl-icd-libopencl1 clinfo\n",
        "sudo apt-get install -y nvidia-opencl-dev opencl-headers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EU-gegvNzP0L",
        "outputId": "ccf211f2-fd36-4224-a639-53108b38a9e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "clinfo is already the newest version (3.0.21.02.21-1).\n",
            "ocl-icd-libopencl1 is already the newest version (2.2.14-3).\n",
            "ocl-icd-libopencl1 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "nvidia-opencl-dev is already the newest version (11.5.1-1ubuntu1).\n",
            "The following NEW packages will be installed:\n",
            "  opencl-headers\n",
            "0 upgraded, 1 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 1,754 B of archives.\n",
            "After this operation, 12.3 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 opencl-headers all 3.0~2022.01.04-1 [1,754 B]\n",
            "Fetched 1,754 B in 0s (4,927 B/s)\n",
            "Selecting previously unselected package opencl-headers.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 125788 files and directories currently installed.)\r\n",
            "Preparing to unpack .../opencl-headers_3.0~2022.01.04-1_all.deb ...\r\n",
            "Unpacking opencl-headers (3.0~2022.01.04-1) ...\r\n",
            "Setting up opencl-headers (3.0~2022.01.04-1) ...\r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git clone --recursive https://github.com/microsoft/LightGBM\n",
        "cd LightGBM\n",
        "mkdir build\n",
        "cd build\n",
        "cmake -DUSE_CUDAP=1 ..\n",
        "make -j4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CzQ6jJN_zVeb",
        "outputId": "f597be82-b0c7-46fa-8ba9-9f26bcc627f2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submodule path 'external_libs/compute': checked out '36350b7de849300bd3d72a05d8bf890ca405a014'\n",
            "Submodule path 'external_libs/eigen': checked out '3147391d946bb4b6c68edd901f2add6ac1f31f8c'\n",
            "Submodule path 'external_libs/fast_double_parser': checked out '252029ddac664370bdda3f0761675785d92a1573'\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp': checked out 'd936052d32a5b7ca08b0199a6724724aea432309'\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion': checked out 'f4cb2384efa55dee0e6652f8674b05763441ab09'\n",
            "Submodule path 'external_libs/fmt': checked out '8303d140a1a11f19b982a9f664bbe59a1ccda3f4'\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP: TRUE (found version \"4.5\")\n",
            "-- Performing Test MM_PREFETCH\n",
            "-- Performing Test MM_PREFETCH - Success\n",
            "-- Using _mm_prefetch\n",
            "-- Performing Test MM_MALLOC\n",
            "-- Performing Test MM_MALLOC - Success\n",
            "-- Using _mm_malloc\n",
            "-- Configuring done (1.4s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/LightGBM/build\n",
            "[  2%] Building CXX object CMakeFiles/lightgbm_capi_objs.dir/src/c_api.cpp.o\n",
            "[  5%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt_model_text.cpp.o\n",
            "[  7%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/boosting.cpp.o\n",
            "[ 10%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt_prediction.cpp.o\n",
            "[ 12%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt.cpp.o\n",
            "[ 15%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/prediction_early_stop.cpp.o\n",
            "[ 17%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/sample_strategy.cpp.o\n",
            "[ 20%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/bin.cpp.o\n",
            "[ 23%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/config_auto.cpp.o\n",
            "[ 25%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/config.cpp.o\n",
            "[ 25%] Built target lightgbm_capi_objs\n",
            "[ 28%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/dataset_loader.cpp.o\n",
            "[ 30%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/dataset.cpp.o\n",
            "[ 33%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/file_io.cpp.o\n",
            "[ 35%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/json11.cpp.o\n",
            "[ 38%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/metadata.cpp.o\n",
            "[ 41%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/parser.cpp.o\n",
            "[ 43%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/train_share_states.cpp.o\n",
            "[ 46%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/tree.cpp.o\n",
            "[ 48%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/metric/dcg_calculator.cpp.o\n",
            "[ 51%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/metric/metric.cpp.o\n",
            "[ 53%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/network/linker_topo.cpp.o\n",
            "[ 56%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/network/linkers_mpi.cpp.o\n",
            "[ 58%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/network/linkers_socket.cpp.o\n",
            "[ 61%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/network/network.cpp.o\n",
            "[ 64%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/objective/objective_function.cpp.o\n",
            "[ 66%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/data_parallel_tree_learner.cpp.o\n",
            "[ 69%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/feature_histogram.cpp.o\n",
            "[ 71%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\n",
            "[ 74%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/gpu_tree_learner.cpp.o\n",
            "[ 76%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/gradient_discretizer.cpp.o\n",
            "[ 79%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/linear_tree_learner.cpp.o\n",
            "[ 82%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/serial_tree_learner.cpp.o\n",
            "[ 84%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/tree_learner.cpp.o\n",
            "[ 87%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\n",
            "[ 89%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/utils/openmp_wrapper.cpp.o\n",
            "[ 89%] Built target lightgbm_objs\n",
            "[ 92%] Linking CXX shared library /content/LightGBM/lib_lightgbm.so\n",
            "[ 94%] Building CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\n",
            "[ 97%] Building CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\n",
            "[ 97%] Built target _lightgbm\n",
            "[100%] Linking CXX executable /content/LightGBM/lightgbm\n",
            "[100%] Built target lightgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'LightGBM'...\n",
            "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'external_libs/compute'\n",
            "Submodule 'eigen' (https://gitlab.com/libeigen/eigen.git) registered for path 'external_libs/eigen'\n",
            "Submodule 'external_libs/fast_double_parser' (https://github.com/lemire/fast_double_parser.git) registered for path 'external_libs/fast_double_parser'\n",
            "Submodule 'external_libs/fmt' (https://github.com/fmtlib/fmt.git) registered for path 'external_libs/fmt'\n",
            "Cloning into '/content/LightGBM/external_libs/compute'...\n",
            "Cloning into '/content/LightGBM/external_libs/eigen'...\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser'...\n",
            "Cloning into '/content/LightGBM/external_libs/fmt'...\n",
            "Submodule 'benchmark/dependencies/abseil-cpp' (https://github.com/abseil/abseil-cpp.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'\n",
            "Submodule 'benchmark/dependencies/double-conversion' (https://github.com/google/double-conversion.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'...\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'...\n",
            "CMake Warning:\n",
            "  Manually-specified variables were not used by the project:\n",
            "\n",
            "    USE_CUDAP\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "print(lgb.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "00mPAW2C0jQ4",
        "outputId": "91116f4d-e76d-4a31-c1d4-8fbf3745b181"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_feature_indexes = [train_inputs.columns.get_loc(col) for col in categorical_cols]"
      ],
      "metadata": {
        "id": "xQY80f6w6M1h"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Перетворення категоріальних ознак у формат category\n",
        "for col in categorical_cols:\n",
        "    train_inputs[col] = train_inputs[col].astype('category')\n",
        "    val_inputs[col] = val_inputs[col].astype('category')\n",
        "\n",
        "# Отримання індексів категоріальних ознак\n",
        "cat_feature_indexes = [train_inputs.columns.get_loc(col) for col in categorical_cols]\n",
        "\n",
        "# Ініціалізація моделі LightGBM\n",
        "lgb_clf = lgb.LGBMClassifier(\n",
        "    max_depth=3,\n",
        "    n_estimators=50,\n",
        "    learning_rate=0.1,\n",
        "    categorical_feature=cat_feature_indexes,  # для автоматичного розпізнавання категорійних ознак\n",
        "    missing=np.nan,  # явне вказування пропущених значень\n",
        "    # device='cuda'  # використовувати GPU для прискорення обчислень\n",
        ")\n",
        "\n",
        "# Навчання моделі\n",
        "lgb_clf.fit(train_inputs, train_targets, eval_set=[(val_inputs, val_targets)])\n",
        "\n",
        "# Прогнозування\n",
        "train_pred = lgb_clf.predict(train_inputs)\n",
        "val_pred = lgb_clf.predict(val_inputs)\n",
        "\n",
        "# Оцінка результатів\n",
        "print(classification_report(train_targets, train_pred, digits=4))\n",
        "print(classification_report(val_targets, val_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Vmyd1WGq1S5T",
        "outputId": "a581b20c-f2e7-45f6-dd37-0c2f69e00b80"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] categorical_feature is set=1,2, categorical_column=1,2 will be ignored. Current value: categorical_feature=1,2\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9184    0.9632    0.9403      9558\n",
            "         1.0     0.8219    0.6650    0.7352      2442\n",
            "\n",
            "    accuracy                         0.9025     12000\n",
            "   macro avg     0.8701    0.8141    0.8377     12000\n",
            "weighted avg     0.8988    0.9025    0.8985     12000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9175    0.9590    0.9378      2390\n",
            "         1.0     0.8048    0.6623    0.7266       610\n",
            "\n",
            "    accuracy                         0.8987      3000\n",
            "   macro avg     0.8612    0.8106    0.8322      3000\n",
            "weighted avg     0.8946    0.8987    0.8949      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для оптимізації гіперпараметрів\n",
        "def objective(params):\n",
        "    clf = lgb.LGBMClassifier(\n",
        "        n_estimators=int(params['n_estimators']),\n",
        "        learning_rate=params['learning_rate'],\n",
        "        max_depth=int(params['max_depth']),\n",
        "        num_leaves=int(params['num_leaves']),\n",
        "        min_child_weight=params['min_child_weight'],\n",
        "        subsample=params['subsample'],\n",
        "        colsample_bytree=params['colsample_bytree'],\n",
        "        reg_alpha=params['reg_alpha'],\n",
        "        reg_lambda=params['reg_lambda'],\n",
        "        min_split_gain=params['min_split_gain'],\n",
        "        categorical_feature=cat_feature_indexes,  # Індекси категорійних ознак\n",
        "        missing=np.nan,\n",
        "        verbose=-1  # Отключение вывода логов модели\n",
        "    )\n",
        "\n",
        "    clf.fit(train_inputs, train_targets, eval_set=[(val_inputs, val_targets)], eval_metric=\"logloss\")\n",
        "    pred = clf.predict(val_inputs)\n",
        "    accuracy = accuracy_score(val_targets, pred)\n",
        "\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
        "\n",
        "# Простір гіперпараметрів\n",
        "space = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 500, 25),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
        "    'max_depth': hp.quniform('max_depth', 3, 15, 1),\n",
        "    'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n",
        "    'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
        "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0, 1),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0, 1),\n",
        "    'min_split_gain': hp.uniform('min_split_gain', 0, 0.1)\n",
        "}\n",
        "\n",
        "# Оптимізація\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10, trials=trials)\n",
        "\n",
        "# Перетворення значень гіперпараметрів у кінцеві типи\n",
        "best['n_estimators'] = int(best['n_estimators'])\n",
        "best['max_depth'] = int(best['max_depth'])\n",
        "best['num_leaves'] = int(best['num_leaves'])\n",
        "best['min_child_weight'] = int(best['min_child_weight'])\n",
        "\n",
        "print(\"Найкращі гіперпараметри: \", best)\n",
        "\n",
        "# Навчання фінальної моделі з найкращими гіперпараметрами\n",
        "final_clf = lgb.LGBMClassifier(\n",
        "    n_estimators=best['n_estimators'],\n",
        "    learning_rate=best['learning_rate'],\n",
        "    max_depth=best['max_depth'],\n",
        "    num_leaves=best['num_leaves'],\n",
        "    min_child_weight=best['min_child_weight'],\n",
        "    subsample=best['subsample'],\n",
        "    colsample_bytree=best['colsample_bytree'],\n",
        "    reg_alpha=best['reg_alpha'],\n",
        "    reg_lambda=best['reg_lambda'],\n",
        "    min_split_gain=best['min_split_gain'],\n",
        "    categorical_feature=cat_feature_indexes,\n",
        "    missing=np.nan,\n",
        "    verbose=-1  # Отключение вывода логов модели\n",
        ")\n",
        "\n",
        "# Обучение модели\n",
        "final_clf.fit(train_inputs, train_targets, eval_set=[(val_inputs, val_targets)], eval_metric=\"logloss\")\n",
        "\n",
        "# Предсказание классов\n",
        "final_pred = final_clf.predict(val_inputs)\n",
        "final_accuracy = accuracy_score(val_targets, final_pred)\n",
        "\n",
        "# Предсказание вероятностей для AUROC\n",
        "train_probs = final_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_probs = final_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "# Вычисление AUROC\n",
        "train_auc = roc_auc_score(train_targets, train_probs)\n",
        "val_auc = roc_auc_score(val_targets, val_probs)\n",
        "\n",
        "# Вывод результатов\n",
        "print(\"AUROC на тренувальній вибірці: {:.4f}\".format(train_auc))\n",
        "print(\"AUROC на валідаційній вибірці: {:.4f}\".format(val_auc))\n",
        "print(\"Точність на валідаційній вибірці: {:.4f}\".format(final_accuracy))\n",
        "print(\"\\nКласифікаційний звіт:\")\n",
        "print(classification_report(val_targets, final_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS52DAcM7duo",
        "outputId": "cd1cf79b-353b-4cea-c552-f8ea00c736fd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10%|█         | 1/10 [00:00<00:06,  1.43trial/s, best loss: -0.89]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20%|██        | 2/10 [00:02<00:10,  1.26s/trial, best loss: -0.8916666666666667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30%|███       | 3/10 [00:03<00:08,  1.22s/trial, best loss: -0.8916666666666667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40%|████      | 4/10 [00:03<00:05,  1.18trial/s, best loss: -0.8916666666666667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50%|█████     | 5/10 [00:04<00:04,  1.19trial/s, best loss: -0.8946666666666667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 60%|██████    | 6/10 [00:05<00:02,  1.41trial/s, best loss: -0.897]             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70%|███████   | 7/10 [00:05<00:02,  1.48trial/s, best loss: -0.9003333333333333]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 80%|████████  | 8/10 [00:06<00:01,  1.79trial/s, best loss: -0.902]             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90%|█████████ | 9/10 [00:07<00:00,  1.28trial/s, best loss: -0.902]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 10/10 [00:07<00:00,  1.27trial/s, best loss: -0.902]\n",
            "Найкращі гіперпараметри:  {'colsample_bytree': 0.6158681877045149, 'learning_rate': 0.19022016814568107, 'max_depth': 3, 'min_child_weight': 9, 'min_split_gain': 0.0931354284327202, 'n_estimators': 225, 'num_leaves': 47, 'reg_alpha': 0.16344002088096765, 'reg_lambda': 0.16844927690919687, 'subsample': 0.884833947889754}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC на тренувальній вибірці: 0.9546\n",
            "AUROC на валідаційній вибірці: 0.9345\n",
            "Точність на валідаційній вибірці: 0.9020\n",
            "\n",
            "Класифікаційний звіт:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9219    0.9582    0.9397      2390\n",
            "         1.0     0.8062    0.6820    0.7389       610\n",
            "\n",
            "    accuracy                         0.9020      3000\n",
            "   macro avg     0.8641    0.8201    0.8393      3000\n",
            "weighted avg     0.8984    0.9020    0.8989      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оптимізація дала незначне покращення у точності та AUROC на тренувальних даних.\n",
        "UROC на валідаційних даних майже не змінилася (мінус 0.24%), що означає, що модель не перенавчилася.\n",
        "\n",
        "Загалом модель стала трохи краще, але ефект оптимізації гіперпараметрів не дуже великий."
      ],
      "metadata": {
        "id": "mY2QqlcCA67u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Оберіть модель з експериментів в цьому ДЗ і зробіть новий `submission` на Kaggle та додайте код для цього і скріншот скора на публічному лідерборді.\n",
        "  \n",
        "  **Напишіть коментар, чому ви обрали саме цю модель?**\n",
        "\n",
        "  І я вас вітаю - це останнє завдання з цим набором даних 💪 На цьому етапі корисно проаналізувати, які моделі показали себе найкраще і подумати, чому."
      ],
      "metadata": {
        "id": "XArADR2CG8VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 🔹 Завантаження тестових даних\n",
        "test_data_path = \"/content/test.csv\"\n",
        "test_df = pd.read_csv(test_data_path)\n",
        "\n",
        "# 🔹 Перевіряємо, чи є 'id' у test_df\n",
        "if 'id' not in test_df.columns:\n",
        "    raise ValueError(\"Колонка 'id' відсутня у тестових даних!\")\n",
        "\n",
        "# 🔹 Видаляємо непотрібні колонки (як у тренувальних даних)\n",
        "input_cols = [col for col in train_inputs.columns]  # Використовуємо ті самі ознаки, що і в train_inputs\n",
        "test_inputs = test_df[input_cols].copy()\n",
        "\n",
        "# 🔹 Гарантія, що категоріальні колонки мають такий самий тип (category)\n",
        "categorical_cols = train_inputs.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "for col in categorical_cols:\n",
        "    test_inputs[col] = test_inputs[col].astype('category')\n",
        "\n",
        "    # 🔹 Переконуємося, що всі категорії з train є в test (додаємо, якщо треба)\n",
        "    test_inputs[col] = test_inputs[col].cat.set_categories(train_inputs[col].cat.categories)\n",
        "\n",
        "# 🔹 **Гарантія, що стовпці test_inputs та train_inputs співпадають**\n",
        "missing_cols = set(train_inputs.columns) - set(test_inputs.columns)\n",
        "\n",
        "# Додаємо відсутні колонки з нулями\n",
        "for col in missing_cols:\n",
        "    test_inputs[col] = 0\n",
        "\n",
        "# 🔹 Упорядковуємо стовпці так само, як у train_inputs\n",
        "test_inputs = test_inputs[train_inputs.columns]\n",
        "\n",
        "# 🔹 Передбачення ймовірностей для тестового набору\n",
        "test_preds = final_clf.predict_proba(test_inputs)[:, 1]  # Ймовірність класу 1 (Exited)\n",
        "\n",
        "# 🔹 Створення `submission.csv`\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],  # Використовуємо реальний ID з test_df\n",
        "    'Exited': test_preds\n",
        "})\n",
        "\n",
        "# 🔹 Збереження у файл CSV\n",
        "submission_path = \"/content/submission.csv\"\n",
        "submission.to_csv(submission_path, index=False)\n",
        "\n",
        "print(f\"✅ Файл submission.csv успішно збережено за шляхом: {submission_path}\")\n",
        "\n",
        "# 🔹 Виведення перших рядків `submission.csv`\n",
        "submission.head()\n"
      ],
      "metadata": {
        "id": "COIjJH9f5SSp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "92a32b33-0bb2-4f25-e8bd-1842e917fdb1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Файл submission.csv успішно збережено за шляхом: /content/submission.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id    Exited\n",
              "0  15000  0.049632\n",
              "1  15001  0.008179\n",
              "2  15002  0.053421\n",
              "3  15003  0.526616\n",
              "4  15004  0.031371"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb136b2b-7aed-4271-8ff5-c419371d7a0d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15000</td>\n",
              "      <td>0.049632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15001</td>\n",
              "      <td>0.008179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15002</td>\n",
              "      <td>0.053421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15003</td>\n",
              "      <td>0.526616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15004</td>\n",
              "      <td>0.031371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb136b2b-7aed-4271-8ff5-c419371d7a0d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb136b2b-7aed-4271-8ff5-c419371d7a0d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb136b2b-7aed-4271-8ff5-c419371d7a0d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97094ea9-1d5e-4262-95c7-d8aec8d597ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97094ea9-1d5e-4262-95c7-d8aec8d597ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97094ea9-1d5e-4262-95c7-d8aec8d597ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission",
              "summary": "{\n  \"name\": \"submission\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2886,\n        \"min\": 15000,\n        \"max\": 24999,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          21252,\n          19684,\n          16731\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Exited\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3087113060414368,\n        \"min\": 0.000509815793201758,\n        \"max\": 0.9997111660697084,\n        \"num_unique_values\": 9995,\n        \"samples\": [\n          0.036604968430505286,\n          0.01029322428341229,\n          0.010602163174085844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ]
}